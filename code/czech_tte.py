#!/usr/bin/env python3
"""
czech_tte.py — Fair day-0 treatment-policy Target Trial Emulation (TTE) for Czech data.

Primary estimand:
    12-month all-cause mortality (ACM) effect of being vaccinated at t0 vs not vaccinated at t0.
Design:
    - Day-0 alignment (no immortal time).
    - Treatment-policy: no censoring at later doses.
    - Common follow-up window [t0, t1] for all.
    - Primary endpoint: ACM. Secondary: COVID-coded mortality. Negative control: non-COVID mortality in months 0–6.
    - IPTW for baseline confounding + overlap diagnostics.
    - Sensitivities: optional +14 day lag (not primary), censor-at-next-dose (not primary).

Expected input files:
    baseline.csv: columns -> person_id, sex (M/F), age (int), district (opt), ltc (0/1, opt),
                  prior_infection_date (YYYY-MM-DD, opt), [any number of extra baseline covariates].
    vax.csv:      columns -> person_id, dose_number (1,2,3,...), vax_date (YYYY-MM-DD), brand (opt).
    events.csv:   columns -> person_id, event_date (YYYY-MM-DD), event_type in
                                {'death_covid','death_noncovid','emigration'}.
                   If you only have death_acm, provide that and set --derive_acm_from_parts=0.
                   If both 'death_covid' and 'death_noncovid' exist, ACM is derived as their union.

Usage (example):
    python czech_tte.py \
        --baseline baseline.csv \
        --vax vax.csv \
        --events events.csv \
        --t0 2021-03-01 \
        --t1 2022-03-01 \
        --age-min 60 --age-max 89 \
        --covars age,sex,ltc,prior_infection \
        --outdir results

Example command for windows:
    python czech_tte.py --baseline .\tte_inputs\baseline.csv --vax .\tte_inputs\vax.csv --events .\tte_inputs\events.csv --t0 2021-06-14 --t1 2022-06-14 --age-min 60 --age-max 89 --covars age,sex,prior_infection --outdir .\results
   
Output:
    - results/summary.txt          : Key estimates.
    - results/overlap_ps.png       : Propensity overlap by arm.
    - results/km_acm.png           : Weighted Kaplan-Meier ACM curves.
    - results/km_noncovid_0_180.png: Negative-control KM (0–180 days).

Dependencies:
    pandas, numpy, matplotlib, lifelines, scikit-learn, statsmodels

Author: Generated by ChatGPT (GPT-5 Thinking)
"""

import argparse
import os
import sys
import json
import math
import warnings
from dataclasses import dataclass, field
from typing import List, Optional, Tuple

import numpy as np
import pandas as pd
from datetime import datetime, timedelta

# plotting
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

# models
from lifelines import CoxPHFitter, KaplanMeierFitter
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import roc_auc_score

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

# -----------------------------
# Helpers
# -----------------------------

def parse_date(s: str) -> datetime:
    return datetime.strptime(s, "%Y-%m-%d")

def to_date(s):
    if pd.isna(s):
        return pd.NaT
    try:
        return pd.to_datetime(s).normalize()
    except Exception:
        return pd.NaT

def days_between(a, b):
    return (b - a).days

def clip_weights(w, lower=0.05, upper=20.0):
    w = np.asarray(w, dtype=float)
    return np.clip(w, lower, upper)

def safe_rate(numer, denom):
    return float(numer) / float(denom) if denom > 0 else np.nan

def printv(msg):
    print(msg, flush=True)

# -----------------------------
# Core data assembly
# -----------------------------

def load_inputs(baseline_path, vax_path, events_path):
    b = pd.read_csv(baseline_path)
    v = pd.read_csv(vax_path)
    e = pd.read_csv(events_path)
    # Standardize
    required_b = ["person_id", "age", "sex"]
    for col in required_b:
        if col not in b.columns:
            raise ValueError(f"baseline.csv missing required column: {col}")
    if "prior_infection_date" not in b.columns:
        b["prior_infection_date"] = pd.NaT
    else:
        b["prior_infection_date"] = pd.to_datetime(b["prior_infection_date"], errors="coerce").dt.normalize()

    required_v = ["person_id", "dose_number", "vax_date"]
    for col in required_v:
        if col not in v.columns:
            raise ValueError(f"vax.csv missing required column: {col}")
    v["vax_date"] = pd.to_datetime(v["vax_date"], errors="coerce").dt.normalize()

    required_e = ["person_id", "event_date", "event_type"]
    for col in required_e:
        if col not in e.columns:
            raise ValueError(f"events.csv missing required column: {col}")
    e["event_date"] = pd.to_datetime(e["event_date"], errors="coerce").dt.normalize()
    return b, v, e

def build_analysis_cohorts(baseline, vax, events, t0: datetime, t1: datetime,
                           age_min=None, age_max=None):
    """Return a dataframe with one row per person with:
       - vaccinated_at_t0 (0/1)
       - time (days) from t0 to event/censor
       - event_acm (0/1), event_covid (0/1), event_noncovid (0/1)
       - baseline covariates carried over
       Treatment-policy: no censoring at later doses; everyone followed to min(death, t1, emigration).
    """
    # Restrict age
    df = baseline.copy()
    if age_min is not None:
        df = df[df["age"] >= age_min]
    if age_max is not None:
        df = df[df["age"] <= age_max]
    df = df.drop_duplicates(subset=["person_id"])

    # Vaccination status at t0
    first_dose = vax.sort_values(["person_id", "dose_number"]).drop_duplicates("person_id", keep="first")
    first_dose = first_dose[["person_id", "vax_date"]].rename(columns={"vax_date": "first_dose_date"})
    df = df.merge(first_dose, on="person_id", how="left")
    df["vaccinated_at_t0"] = (df["first_dose_date"].notna()) & (df["first_dose_date"] <= pd.Timestamp(t0))
    df["vaccinated_at_t0"] = df["vaccinated_at_t0"].astype(int)

    # Outcomes: earliest death, categorize
    ev = events[events["event_type"].isin(["death_covid","death_noncovid","death_acm","emigration"])].copy()
    # derive ACM if necessary
    has_parts = set(ev["event_type"].unique())
    if "death_acm" not in has_parts:
        # derive ACM as min(covid, noncovid)
        covid = ev[ev["event_type"]=="death_covid"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("death_covid_date")
        nonc = ev[ev["event_type"]=="death_noncovid"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("death_noncovid_date")
        acm = pd.concat([covid, nonc], axis=1)
        acm["death_acm_date"] = acm.min(axis=1)
        # Merge back
        df = df.merge(acm, left_on="person_id", right_index=True, how="left")
    else:
        acm = ev[ev["event_type"]=="death_acm"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("death_acm_date")
        covid = ev[ev["event_type"]=="death_covid"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("death_covid_date")
        nonc  = ev[ev["event_type"]=="death_noncovid"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("death_noncovid_date")
        df = df.merge(acm, left_on="person_id", right_index=True, how="left")
        df = df.merge(covid, left_on="person_id", right_index=True, how="left")
        df = df.merge(nonc, left_on="person_id", right_index=True, how="left")

    # Emigration (censoring)
    emi = ev[ev["event_type"]=="emigration"][["person_id","event_date"]].groupby("person_id").event_date.min().rename("emigration_date")
    df = df.merge(emi, left_on="person_id", right_index=True, how="left")

    # Follow-up end
    df["t0"] = pd.Timestamp(t0)
    df["t1"] = pd.Timestamp(t1)
    df["end_of_fu"] = df[["death_acm_date","emigration_date"]].min(axis=1)
    df["end_of_fu"] = df["end_of_fu"].fillna(df["t1"])
    df["end_of_fu"] = df[["end_of_fu","t1"]].min(axis=1)

    # Time and events
    df["time"] = (df["end_of_fu"] - df["t0"]).dt.days.clip(lower=0)
    df["event_acm"] = ((df["death_acm_date"].notna()) & (df["death_acm_date"] <= df["end_of_fu"])).astype(int)
    df["event_covid"] = ((df["death_covid_date"].notna()) & (df["death_covid_date"] <= df["end_of_fu"])).astype(int)
    df["event_noncovid"] = ((df["death_noncovid_date"].notna()) & (df["death_noncovid_date"] <= df["end_of_fu"])).astype(int)

    # Negative-control early window indicator
    df["time_180"] = np.minimum(df["time"], 180)
    df["event_noncovid_0_180"] = 0
    mask_nc = df["death_noncovid_date"].notna() & (df["death_noncovid_date"] <= (df["t0"] + pd.Timedelta(days=180)))
    df.loc[mask_nc, "event_noncovid_0_180"] = 1

    return df

# -----------------------------
# IPTW & diagnostics
# -----------------------------

def build_propensity_and_weights(df, covars: List[str], treat_col="vaccinated_at_t0",
                                 stabilize=True, clip=(0.05, 20.0), outdir=None):
    X = df[covars].copy()
    y = df[treat_col].astype(int).values

    # Split columns by type
    num_cols = [c for c in covars if np.issubdtype(X[c].dtype, np.number)]
    cat_cols = [c for c in covars if c not in num_cols]

    pre = ColumnTransformer([
        ("num", StandardScaler(), num_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols)
    ])

    model = Pipeline([("pre", pre), ("clf", LogisticRegression(max_iter=200, solver="lbfgs"))])
    model.fit(X, y)
    ps = model.predict_proba(X)[:,1]
    auc = roc_auc_score(y, ps) if len(np.unique(y)) > 1 else np.nan

    # Stabilized IPTW
    p_treated = y.mean()
    eps = 1e-6
    ps = np.clip(ps, eps, 1 - eps)
    if stabilize:
        w = np.where(y==1, p_treated/ps, (1-p_treated)/(1-ps))
    else:
        w = np.where(y==1, 1/ps, 1/(1-ps))
    w = clip_weights(w, clip[0], clip[1])

    df_out = df.copy()
    df_out["pscore"] = ps
    df_out["iptw"] = w

    # Overlap plot
    if outdir is not None:
        fig = plt.figure(figsize=(6,4), dpi=150)
        treated_ps = df_out.loc[df_out[treat_col]==1, "pscore"].values
        control_ps = df_out.loc[df_out[treat_col]==0, "pscore"].values
        plt.hist(treated_ps, bins=30, alpha=0.5, label="vaccinated_at_t0=1", density=True)
        plt.hist(control_ps, bins=30, alpha=0.5, label="vaccinated_at_t0=0", density=True)
        plt.xlabel("Propensity score")
        plt.ylabel("Density")
        plt.title(f"Propensity overlap (AUC={auc:.3f})")
        plt.legend()
        plt.tight_layout()
        plt.savefig(os.path.join(outdir, "overlap_ps.png"))
        plt.close(fig)

    return df_out, auc

# -----------------------------
# Survival analyses
# -----------------------------

def weighted_km_plot(df, duration_col, event_col, group_col, weight_col, out_png, title):
    km = KaplanMeierFitter()
    fig = plt.figure(figsize=(6,4), dpi=150)
    for g in sorted(df[group_col].unique()):
        sub = df[df[group_col]==g]
        km.fit(durations=sub[duration_col], event_observed=sub[event_col], weights=sub[weight_col], label=f"{group_col}={g}")
        km.plot()
    plt.title(title)
    plt.xlabel("Days since t0")
    plt.ylabel("Survival probability")
    plt.tight_layout()
    plt.savefig(out_png)
    plt.close(fig)

def risk_ratio_km(df, horizon_days=365, duration_col="time", event_col="event_acm", group_col="vaccinated_at_t0", weight_col="iptw"):
    # Estimate risk at horizon using KM: risk = 1 - S(horizon)
    km = KaplanMeierFitter()
    risks = {}
    for g in [0,1]:
        sub = df[df[group_col]==g]
        km.fit(sub[duration_col], event_observed=sub[event_col], weights=sub[weight_col])
        surv = km.survival_function_at_times(horizon_days).values[0]
        risks[g] = 1.0 - float(surv)
    rr = risks[1] / risks[0] if risks[0] > 0 else np.nan
    return rr, risks

def cox_hr(df, duration_col="time", event_col="event_acm", weight_col="iptw", covars_adjust=None):
    # Model includes treatment + covars_adjust
    data = df.copy()
    cols = []
    data["treat"] = data["vaccinated_at_t0"].astype(int)
    cols.append("treat")
    if covars_adjust:
        cols += covars_adjust
    
    # Create a subset with only the needed columns
    data2 = data[[duration_col, event_col, "treat"] + (covars_adjust or []) + ([weight_col] if weight_col else [])].copy()
    
    # Handle categorical variables by converting to dummy variables
    categorical_cols = []
    for col in (covars_adjust or []):
        if col in data2.columns and data2[col].dtype == 'object':
            categorical_cols.append(col)
    
    if categorical_cols:
        # Create dummy variables for categorical columns
        data2 = pd.get_dummies(data2, columns=categorical_cols, drop_first=True, dtype=float)
    
    # Drop rows with missing values
    data2 = data2.dropna()
    printv(f"Cox model input: {len(data2)} observations, {data2[event_col].sum()} events")
    
    # Fit Cox model
    cph = CoxPHFitter()
    printv("Starting Cox model fitting...")
    cph.fit(data2, duration_col=duration_col, event_col=event_col, weights_col=weight_col, robust=False)
    
    # Extract treatment effect
    hr = math.exp(cph.params_["treat"])
    se = cph.standard_errors_["treat"]
    # 95% CI
    lcl = math.exp(cph.params_["treat"] - 1.96*se)
    ucl = math.exp(cph.params_["treat"] + 1.96*se)
    return hr, (lcl, ucl), cph

# -----------------------------
# Main
# -----------------------------

def main():
    ap = argparse.ArgumentParser(description="Fair day-0 treatment-policy TTE on Czech data")
    ap.add_argument("--baseline", required=True, help="Path to baseline CSV")
    ap.add_argument("--vax", required=True, help="Path to vaccination CSV (long format)")
    ap.add_argument("--events", required=True, help="Path to events CSV")
    ap.add_argument("--t0", required=True, help="Analysis start date YYYY-MM-DD")
    ap.add_argument("--t1", required=True, help="Analysis end date YYYY-MM-DD")
    ap.add_argument("--age-min", type=int, default=None)
    ap.add_argument("--age-max", type=int, default=None)
    ap.add_argument("--covars", type=str, default="age,sex")
    ap.add_argument("--outdir", type=str, default="results")
    ap.add_argument("--clip-low", type=float, default=0.05)
    ap.add_argument("--clip-high", type=float, default=20.0)
    ap.add_argument("--lag14", action="store_true", help="Optional sensitivity: start at t0+14d (NOT PRIMARY)")
    ap.add_argument("--censor_at_next_dose", action="store_true", help="Optional sensitivity: censor at later dose (NOT PRIMARY)")
    args = ap.parse_args()

    os.makedirs(args.outdir, exist_ok=True)
    t0 = parse_date(args.t0)
    t1 = parse_date(args.t1)
    covars = [c.strip() for c in args.covars.split(",") if c.strip()]

    printv("Loading data...")
    baseline, vax, events = load_inputs(args.baseline, args.vax, args.events)

    # Optional censoring at next dose (sensitivity only); for primary we don't censor.
    if args.censor_at_next_dose:
        vax_sorted = vax.sort_values(["person_id","dose_number"])
        next_dose = vax_sorted.groupby("person_id").vax_date.shift(-1).rename("next_dose_date")
        vax_sorted = pd.concat([vax_sorted, next_dose], axis=1)
        # If censoring is desired, we can later use next_dose_date to bound t1 per person.
        vax_next = vax_sorted[['person_id','next_dose_date']].dropna().drop_duplicates('person_id')
    else:
        vax_next = pd.DataFrame(columns=['person_id','next_dose_date'])

    printv("Building analysis cohorts...")
    df = build_analysis_cohorts(baseline, vax, events, t0, t1, args.age_min, args.age_max)

    # If lag14 sensitivity is set, shift t0 by 14 days for both arms (NOTE: not primary)
    if args.lag14:
        df["time"] = np.maximum(0, df["time"] - 14)
        # Recompute early-window indicator for negative control under lag
        df["time_180"] = np.minimum(df["time"], 180)

    # Merge censor-at-next-dose sensitivity bound
    if args.censor_at_next_dose and not vax_next.empty:
        df = df.merge(vax_next, on="person_id", how="left")
        df["end_of_fu"] = np.where(df["next_dose_date"].notna(),
                                   np.minimum(df["end_of_fu"], df["next_dose_date"]),
                                   df["end_of_fu"])
        df["time"] = (pd.to_datetime(df["end_of_fu"]) - pd.to_datetime(df["t0"])).dt.days.clip(lower=0)
        # Recompute events under earlier censoring
        df["event_acm"] = ((df["death_acm_date"].notna()) & (df["death_acm_date"] <= df["end_of_fu"])).astype(int)
        df["event_covid"] = ((df["death_covid_date"].notna()) & (df["death_covid_date"] <= df["end_of_fu"])).astype(int)
        df["event_noncovid"] = ((df["death_noncovid_date"].notna()) & (df["death_noncovid_date"] <= df["end_of_fu"])).astype(int)

    # Make simple baseline covariates: prior_infection as binary by t0 if present
    if "prior_infection_date" in df.columns:
        df["prior_infection"] = (df["prior_infection_date"].notna()) & (df["prior_infection_date"] < pd.Timestamp(t0))
        if "prior_infection" not in covars:
            # add if referenced in default stub
            pass

    # Keep only needed columns, ensure covars present
    missing_covars = [c for c in covars if c not in df.columns]
    if missing_covars:
        printv(f"WARNING: Missing covariates in data: {missing_covars}. They will be ignored.")
        covars = [c for c in covars if c in df.columns]

    printv("Estimating propensity and IPTW...")
    df_w, auc = build_propensity_and_weights(df, covars=covars, clip=(args.clip_low, args.clip_high),
                                             outdir=args.outdir)

    # Primary ACM analysis
    printv("Running ACM analyses (KM + Cox)...")
    printv(f"Dataset size: {len(df_w)} observations, {df_w['event_acm'].sum()} events")
    km_png = os.path.join(args.outdir, "km_acm.png")
    weighted_km_plot(df_w, "time", "event_acm", "vaccinated_at_t0", "iptw", km_png, "Weighted KM: All-cause mortality")

    printv("Computing KM risk ratios...")
    rr_365, risks = risk_ratio_km(df_w, horizon_days=365, duration_col="time", event_col="event_acm",
                                  group_col="vaccinated_at_t0", weight_col="iptw")

    printv("Fitting Cox model for ACM (this may take a while with large datasets)...")
    # For very large datasets, consider sampling for initial testing
    # df_w_sample = df_w.sample(frac=0.1, random_state=42)  # Use 10% sample
    hr_acm, (lcl_acm, ucl_acm), cph_acm = cox_hr(df_w, duration_col="time", event_col="event_acm",
                                                 weight_col="iptw", covars_adjust=covars)

    # Negative control: non-COVID 0–180 days (KM only) + Cox on non-COVID over full t1
    km_nc_png = os.path.join(args.outdir, "km_noncovid_0_180.png")
    # create truncated df for 180-day KM
    df_nc = df_w.copy()
    df_nc["time_nc"] = df_nc["time_180"]
    weighted_km_plot(df_nc, "time_nc", "event_noncovid_0_180", "vaccinated_at_t0", "iptw",
                     km_nc_png, "Weighted KM: non-COVID mortality (0–180 days)")

    hr_nc, (lcl_nc, ucl_nc), cph_nc = cox_hr(df_w, duration_col="time", event_col="event_noncovid",
                                             weight_col="iptw", covars_adjust=covars)

    # COVID-coded mortality (secondary)
    hr_covid, (lcl_covid, ucl_covid), cph_covid = cox_hr(df_w, duration_col="time", event_col="event_covid",
                                                         weight_col="iptw", covars_adjust=covars)

    # Crude counts / rates for transparency
    out = []
    for g in [0,1]:
        sub = df_w[df_w["vaccinated_at_t0"]==g]
        n = len(sub)
        deaths = sub["event_acm"].sum()
        person_days = sub["time"].sum()
        out.append((g, n, int(deaths), int(person_days)))

    summary = []
    summary.append("=== Fair day-0 TTE (treatment-policy) ===")
    summary.append(f"t0={args.t0}  t1={args.t1}  age_min={args.age_min}  age_max={args.age_max}")
    summary.append(f"Sample size: N={len(df_w)}")
    summary.append(f"Propensity AUC={auc:.3f}")
    summary.append("Cohort counts (vaccinated_at_t0, N, deaths_acm, person-days):")
    for row in out:
        summary.append(f"  {row[0]}: N={row[1]}, deaths={row[2]}, person_days={row[3]}")
    summary.append("")
    summary.append(f"Weighted KM 365-day ACM risk ratio (vaccinated/unvaccinated): RR={rr_365:.3f}")
    summary.append(f"CoxPH ACM HR (IPTW-weighted): HR={hr_acm:.3f}  95%CI=({lcl_acm:.3f},{ucl_acm:.3f})")
    summary.append("")
    summary.append(f"Negative control (non-COVID) Cox HR over full follow-up: HR={hr_nc:.3f}  95%CI=({lcl_nc:.3f},{ucl_nc:.3f})")
    summary.append(f"Secondary (COVID-coded death) Cox HR: HR={hr_covid:.3f}  95%CI=({lcl_covid:.3f},{ucl_covid:.3f})")
    summary.append("")
    summary.append("Notes:")
    summary.append("- Primary estimand is ACM under treatment-policy with day-0 alignment.")
    summary.append("- Negative-control expectation: HR ~ 1.0 in months 0–6 if residual HVE is minimal.")
    summary.append("- Sensitivities: Use --lag14 and/or --censor_at_next_dose; primary results should not hinge on them.")
    summary.append("- Always inspect overlap_ps.png; poor overlap undermines identifiability.")

    with open(os.path.join(args.outdir, "summary.txt"), "w", encoding="utf-8") as f:
        f.write("\n".join(summary))

    for line in summary:
        printv(line)

if __name__ == "__main__":
    main()
